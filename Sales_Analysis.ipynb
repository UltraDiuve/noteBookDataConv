{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports et setup\n",
    "## Imports des bibliothèques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import timeit\n",
    "\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "from pandas.api.types import union_categoricals, CategoricalDtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup des outils de visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', None)\n",
    "register_matplotlib_converters()\n",
    "sns.set(style=\"ticks\", color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement du Dataset\n",
    "\n",
    "## Définition des fichiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# historiques de vente\n",
    "file_list = ['./Data/LDV_CONV_1ALO_201707_201906_V3.csv',\n",
    "             './Data/LDV_CONV_1ALO_V3_20190909.csv', \n",
    "             './Data/LDV_CONV_1ALO_V3_20190916.csv', \n",
    "             './Data/LDV_CONV_1ALO_V3_20191011.csv',\n",
    "             './Data/LDV_CONV_1ALO_V3_20191024.csv']\n",
    "\n",
    "client_filename = './Data/Référentiel_ConverteO_1ALO_Clt_20191024.csv'\n",
    "material_filename = './Data/Référentiel_ConverteO_1ALO_Art_20191024.csv'\n",
    "scope_filename = './Data/split_cli_test_reco.csv'\n",
    "\n",
    "# Pour le moment, on n'intègre que le dernier fichier de reco\n",
    "previous_reco_filename = './Data/Recos_KNN_post_filtres_20191024.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historiques de vente\n",
    "\n",
    "Définition du format, et de l'index cible (une fois la concaténation effectuée)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fields = {'orgacom':'category',\n",
    "          'month':'category',\n",
    "          'week':'category',\n",
    "          'date':'object',\n",
    "          'pricetype':'category',\n",
    "          'client':'object',\n",
    "          'doctype':'category',\n",
    "          'origin':'category',\n",
    "          'salesgroup':'category',\n",
    "          'material':'object',\n",
    "          'brutrevenue':'float',\n",
    "          'brutrevcur':'category', \n",
    "          'netrevenue':'float', \n",
    "          'netrevcur':'category',\n",
    "          'weight':'float',\n",
    "          'weightunit':'category',\n",
    "          'marginperkg':'float'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Définition d'une fonction qui permet de concaténer les lignes d'historiques sur des fichiers transmis. Elle permet de concaténer des Dataframes (df1, df2, ..., dfN) dans l'ordre, avec la règle de gestion suivante : si une date est présente sur au moins une ligne du Dataframe df(n+1), toutes les lignes avec cette date sont supprimées du Dataframe df(n) avant concaténation.\n",
    "\n",
    "C'est l'argument 'concat_index' qui va permettre d'identifier sur quelle donnée effectuer ces filtres successifs. Si 'concat_index' est passé avec 'date', alors si une date est présente dans un fichier alors qu'elle était dans un des fichiers précédents, alors elle est droppée (au profit du contenu du nouveau fichier).\n",
    "\n",
    "De plus, les catégories sont alignées au fil de l'eau afin que la concaténation ne se traduisent pas par un upcast vers 'object'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(file_list, **kwargs):\n",
    "    for file_path in file_list:\n",
    "        if 'df' not in locals():\n",
    "            print('Loading ' + file_path)\n",
    "            df = pd.read_csv(file_path, **kwargs)\n",
    "        else:\n",
    "            print('Loading ' + file_path)\n",
    "            df2 = pd.read_csv(file_path, **kwargs)\n",
    "            for field, my_type in fields.items():\n",
    "                if my_type == 'category':\n",
    "                    uc = union_categoricals([df[field],df2[field]])\n",
    "                    df[field] = pd.Categorical( df[field], categories=uc.categories )\n",
    "                    df2[field] = pd.Categorical( df2[field], categories=uc.categories )\n",
    "            df = pd.concat([df[~df.index.isin(df2.index)] ,df2])\n",
    "    print('Done!')\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chargement des fichiers du dataset :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat_index = ['date']\n",
    "\n",
    "df = concat_df(file_list,\n",
    "               sep=';', \n",
    "               header=None, \n",
    "               names=fields.keys(), \n",
    "               dtype=fields, \n",
    "               parse_dates=['date'], \n",
    "               index_col=concat_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On détruit l'index 'date', qui n'a que peu de sens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clients\n",
    "\n",
    "### Chargement\n",
    "\n",
    "On commence par charger le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'code client':'object',\n",
    "          'libellé client':'object',\n",
    "          'code catégorie client':'category',\n",
    "          'libellé catéorie client':'category', \n",
    "          'KNA1-KATR5':'category',\n",
    "          'KNA1-LOEVM':'category',\n",
    "          'KNVV-LOEVM':'category',\n",
    "          'KNVV-PLTYP':'category',\n",
    "          'colonne_source_reco':'category',\n",
    "          'GrVd':'category',\n",
    "          'OrgCm':'category',\n",
    "          'CDis':'category', \n",
    "          'Groupe':'category', \n",
    "          'P.':'category',\n",
    "          'Cde postal':'category', \n",
    "          'KNA1-KATR1':'category', \n",
    "          'KNA1-KATR2':'category', \n",
    "          'KNA1-KATR3':'category', \n",
    "          'KNA1-KATR4':'category', \n",
    "          'KNA1-KATR6':'category'}\n",
    "\n",
    "df_clt = pd.read_csv(client_filename, \n",
    "                     sep=';', \n",
    "                     header=0, \n",
    "                     encoding=\"ISO-8859-1\", \n",
    "                     dtype=fields)\n",
    "df_clt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On ajoute les zéros au niveau du code client, pour pouvoir joindre avec la table des historiques de vente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clt['code client'] = df_clt['code client'].apply(lambda x: x.zfill(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajout et tri de l'index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clt.set_index('code client', inplace=True)\n",
    "df_clt.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On contrôle qu'il n'y a pas de code client en double."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if np.any(df_clt.index.duplicated(keep=False)):\n",
    "    raise RuntimeError('Attention ! Il existe des doublons sur l\\'index du DataFrame df_clt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clt.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse\n",
    "\n",
    "On peut vérifier par exemple la répartition des clients pour chacun des différents niveaux de segmentation :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_index = ['KNA1-KATR1', 'KNA1-KATR2', 'KNA1-KATR3', 'KNA1-KATR4', 'KNA1-KATR5', 'KNA1-KATR6', 'code client']\n",
    "df_clt.reset_index().set_index(new_index).sort_index().head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on regarde uniquement la répartition des clients par segment, jusqu'à la restauration commerciale indépendante, et enfin en y filtrant les traiteurs (catégorie ZY) on obtient : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segments = ['Z3', 'Z5', 'ZK', 'ZG']\n",
    "filter = ['df_clt[\\'KNA1-KATR' + str(i) + '\\'] == \\'' + segments[i-1] + '\\', \\'KNA1-KATR' + str(i+1) + '\\'' for i in range(1, 5)]\n",
    "filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(5, 1, figsize=(7,20))\n",
    "fig.subplots_adjust(hspace=0.5)\n",
    "\n",
    "temp_df = df_clt.loc[:, 'KNA1-KATR1'].value_counts().sort_index()\n",
    "colors = ['C0'] * len(temp_df.index)\n",
    "colors[temp_df.index.get_loc(segments[0])] = 'green'\n",
    "temp_df.plot(kind='bar', ax=axs[0], color=colors)\n",
    "axs[0].set_title('Racine', fontsize=18)\n",
    "\n",
    "for i in range(1, 5):\n",
    "    temp_df = df_clt.loc[eval(filter[i-1])].value_counts().sort_index().loc[lambda x: x>0]\n",
    "    colors = ['C0'] * len(temp_df.index)\n",
    "    if i<4:\n",
    "        colors[temp_df.index.get_loc(segments[i])] = 'green'\n",
    "    else: \n",
    "        colors = ['green'] * len(temp_df.index)\n",
    "        colors[temp_df.index.get_loc('ZY')] = 'red'\n",
    "    temp_df.plot(kind='bar', ax=axs[i], color=colors)\n",
    "    axs[i].set_title('Enfant de ' + ' - '.join(segments[:i]), fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'code article':'object',\n",
    "          'libellé article':'category',\n",
    "          'code gamme':'category',\n",
    "          'libellé gamme':'category', \n",
    "          'MARC-MMSTA':'category',\n",
    "          'MARC-LVORM':'category',\n",
    "          'MVKE-LVORM':'category',\n",
    "          'MVKE-MVSTA':'category',\n",
    "          'MARA-LVORM':'category',\n",
    "          'Hiérarchie produit':'category',\n",
    "          'Type d\\'article':'category',\n",
    "          'Division':'category', \n",
    "          'Org. commerciale':'category', \n",
    "          'Canal distribution':'category',\n",
    "          'File d\\'achat':'category', \n",
    "          'Marque industrielle':'category', \n",
    "          'Marque commerciale':'category', \n",
    "          'Grpe de marchandises':'category', \n",
    "          'Poids net':'float', \n",
    "          'Unité de p':'category',\n",
    "          'V1':'category',\n",
    "          'V2':'category',\n",
    "          'V3':'category',\n",
    "          'LG1':'category',\n",
    "          'LG2':'category',         \n",
    "         }\n",
    "\n",
    "df_mat = pd.read_csv(material_filename, \n",
    "                     sep=';', \n",
    "                     header=0, \n",
    "                     encoding=\"ISO-8859-1\", \n",
    "                     dtype=fields,\n",
    "                     decimal=\",\")\n",
    "df_mat.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat['code article'] = df_mat['code article'].apply(lambda x: x.zfill(18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat.set_index('code article', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Périmètre client\n",
    "\n",
    "On récupère le périmètre client, et on ajoute cette info au dataset client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'code article':'object',\n",
    "          'GrVd':'category',\n",
    "          'code_client':'object', \n",
    "          'marge_livraison_moy_cli':'float',\n",
    "          'rank_MLV_intra_GV':'int64', \n",
    "          'flag_reco':'int64',\n",
    "          'groupe_test':'category'\n",
    "         }\n",
    "\n",
    "df_perim_clt = pd.read_csv(scope_filename, \n",
    "                           sep=';', \n",
    "                           header=0, \n",
    "                           dtype=fields)\n",
    "df_perim_clt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_perim_clt['code_client'] = df_perim_clt['code_client'].str.zfill(10)\n",
    "df_perim_clt.set_index('code_client', inplace=True)\n",
    "df_perim_clt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_perim_clt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clt['flag_reco'] = 0\n",
    "df_clt.update(df_perim_clt['flag_reco'])\n",
    "df_clt['flag_reco'] = df_clt['flag_reco'].astype(np.int64)\n",
    "df_clt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clt.groupby('flag_reco').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_perim_clt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommandations précédentes\n",
    "\n",
    "On commence par charger le fichier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = {'Code_client':'object',\n",
    "          'Code_article':'object',\n",
    "          'xcom':'category',\n",
    "          'xdelais':'category',\n",
    "          'mailDemandeur':'category',\n",
    "          'libelleClient':'object',\n",
    "          'libelleArticle':'object',\n",
    "          'origine':'category',\n",
    "          'rang':'int64',\n",
    "          'rating':'float64'\n",
    "         }\n",
    "\n",
    "df_prev_reco = pd.read_csv(previous_reco_filename, \n",
    "                          sep=';', \n",
    "                          header=0, \n",
    "                          dtype=fields,\n",
    "                          encoding=\"ISO-8859-1\")\n",
    "\n",
    "df_prev_reco.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On met à jour le code article (zéro fillé sur 18 digits).\n",
    "\n",
    "On récupère certains champs du dataframe article (pour le moment, la hiérarchie produit)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_prev_reco['Code_article'] = df_prev_reco['Code_article'].apply(lambda x: x.zfill(18))\n",
    "df_prev_reco = df_prev_reco.set_index('Code_article').join(df_mat['Hiérarchie produit']).reset_index()\n",
    "df_prev_reco.rename(columns={'index':'Code_article'}, inplace=True)\n",
    "df_prev_reco.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df_clt, how='left', left_on=['client'], right_index=True, validate='m:1')\n",
    "df = df.merge(df_mat, how='left', left_on='material', right_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtre sur les types de documents à conserver\n",
    "\n",
    "On ne conserve que les lignes qui concernent des commandes de vente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_doctypes = ['ZC01', 'ZC02', 'ZC10']\n",
    "df = df[df.doctype.isin(filtered_doctypes)].copy()\n",
    "cat_type = CategoricalDtype(categories=['ZC10', 'ZC01', 'ZC02'], ordered=True)\n",
    "df['doctype'] = df['doctype'].astype(cat_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by='doctype').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_clt\n",
    "del df_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filtre sur les lignes de traiteurs\n",
    "\n",
    "On retire les lignes de traiteur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "color = ['green'] * 9\n",
    "color[8] = 'red'\n",
    "df.loc[:, 'KNA1-KATR5'].value_counts().sort_index().loc[lambda x: x>0].plot(kind='bar', color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remarque : cette fois, on n'est plus sur un nombre de clients, mais sur un nombre de lignes dans le dataset d'historiques de vente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['KNA1-KATR5'] == 'ZY'].index, inplace=True)\n",
    "df.loc[:, 'KNA1-KATR5'].value_counts().sort_index().loc[lambda x: x>0].plot(kind='bar', color=color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les lignes du dataset concernant les traiteurs on disparu."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse des premiers ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que certains ratios sont nuls (CA et poids), ce qui risque de poser problème lors du calcul de nouveaux indicateurs (ex : prix de vente au kg, marge %, ...)\n",
    "\n",
    "On va commencer par analyser les incohérences potentielles, en identifiant les relations pour lesquelles les ratios nuls sont incohérents entre eux.\n",
    "\n",
    "On abandonne la notion de CA net net, qui est une donnée purement \"gestion\" et pas commerciale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_type = pd.api.types.CategoricalDtype(categories=['neg', 'nul', 'pos'],\n",
    "                            ordered=True)\n",
    "\n",
    "df['rev_cat'] = 'pos'\n",
    "df.loc[df['brutrevenue'] == 0, 'rev_cat'] = 'nul'\n",
    "df['rev_cat'] = df['rev_cat'].astype(cat_type)\n",
    "df['wei_cat'] = 'pos'\n",
    "df.loc[df['weight'] == 0, 'wei_cat'] = 'nul'\n",
    "df['wei_cat'] = df['wei_cat'].astype(cat_type)\n",
    "df['mrg_cat'] = 'pos'\n",
    "df.loc[df['marginperkg'] == 0, 'mrg_cat'] = 'nul'\n",
    "df.loc[df['marginperkg'] < 0, 'mrg_cat'] = 'neg'\n",
    "df['mrg_cat'] = df['mrg_cat'].astype(cat_type)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(by=['rev_cat', 'wei_cat', 'mrg_cat'])['material'].count().unstack()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on regarde les ratios ci-dessus, partant des plus représentés : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['rev_cat', 'wei_cat', 'mrg_cat'])['material'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pos / pos / pos : on a un CA, un poids et une marge positive. Parfait.\n",
    "\n",
    "nul / nul / nul : on dirait des annulations de ligne. On va supprimer ces lignes du dataset. Cf. le résultat de la requête : \n",
    "df.loc[(df['client'] == '0000262869')].set_index(['material', 'date']).sort_index() : on voit que les lignes \"nulles\" sont le pendant de lignes commandées.\n",
    "\n",
    "pos / pos / neg : c'est quand on vend mal... on les garde.\n",
    "\n",
    "nul / pos / neg : on dirait des gratuits. On garde.\n",
    "\n",
    "pos / pos / pos : on vend plutôt mal, avec une marge nulle. On garde.\n",
    "\n",
    "nul / pos / pos : cas bizarre, on dirait des postes de gratuit, avec une erreur sur le PRN ? Ne concerne que l'article 197832. On droppe.\n",
    "\n",
    "pos / nul / nul : article de service, forfait livraison. On droppe également.\n",
    "\n",
    "nul / pos / nul : commande échantillon, sur un unique produit. Le PRN n'était peut être pas à jour. On droppe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cette cellule permet de contrôler le contenu du dataset pour les différentes combinaisons.\n",
    "df.loc[(df['rev_cat'] == 'nul') & (df['wei_cat'] == 'pos') & (df['mrg_cat'] == 'nul')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~((df['rev_cat'] == 'nul') & (df['wei_cat'] == 'nul') & (df['mrg_cat'] == 'nul'))]\n",
    "df = df.loc[~((df['rev_cat'] == 'pos') & (df['wei_cat'] == 'nul') & (df['mrg_cat'] == 'nul'))]\n",
    "df = df.loc[~((df['rev_cat'] == 'nul') & (df['wei_cat'] == 'pos') & (df['mrg_cat'] == 'pos'))]\n",
    "df = df.loc[~((df['rev_cat'] == 'nul') & (df['wei_cat'] == 'pos') & (df['mrg_cat'] == 'nul'))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(by=['rev_cat', 'wei_cat', 'mrg_cat'])['material'].count().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul de la marge (sur CA brut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['margin'] = df['weight'] * df['marginperkg']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.loc[:, ['brutrevenue', 'weight', 'margin']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que la représentation du dataset est complètement écrasée par les outliers.\n",
    "\n",
    "On va clipper ces outliers, sur ces 3 ratios, puis recalculer les ratios initiaux (en particulier, marge en €/kg). \n",
    "\n",
    "On calcule d'abord les valeurs limites pour les ratios CA brut, Poids du poste et Marge du poste, en bornant à 3 écarts-types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipvalue(series, stdcount=3):\n",
    "    return(series.mean() + stdcount * series.std())\n",
    "\n",
    "ratios = ['brutrevenue', 'weight', 'margin']\n",
    "clipvals = {ratio : clipvalue(df.loc[:, ratio], stdcount=3) for ratio in ratios}\n",
    "\n",
    "print(clipvals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule les nouveaux ratios, et on compare aux ratios initiaux."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ratio, clipval in clipvals.items():\n",
    "    print(ratio + ' en cours de traitement')\n",
    "    print(clipval)\n",
    "    df[ratio + '_clipped'] = df[ratio].clip(lower=-clipval, upper=clipval)\n",
    "\n",
    "# on recalcule la marge au kg pour avoir de la cohérence\n",
    "df['marginperkg_clipped'] = df['margin_clipped'] / df['weight_clipped']\n",
    "    \n",
    "df=df.copy()\n",
    "df[['brutrevenue', 'brutrevenue_clipped', 'weight', 'weight_clipped', 'margin', 'margin_clipped', 'marginperkg', 'marginperkg_clipped']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les valeurs moyennes des ratios sont légèrement plus faibles, les écarts types et les valeurs max se sont fortement réduits.\n",
    "\n",
    "On va à nouveau tenter de représenter la distribution des points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df.loc[:, ['brutrevenue_clipped', 'weight_clipped', 'margin_clipped']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La représentation comporte trop de points pour pouvoir conclure. On analysera un peu plus dans un autre chapitre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul du PMVK\n",
    "\n",
    "On calcule le prix moyen de vente au kilo sur la base des valeurs clippées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pmvk'] = df['brutrevenue_clipped'] / df['weight_clipped']\n",
    "df['pmvk'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df['pmvk'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a à nouveau des outliers sur cette nouvelle donnée, qui \"écrasent\" la distribution. Si on regarde les pmvk les plus gros : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values('pmvk', ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au-delà de quelques erreurs de prix, on voit que l'article 9800085 Conservateur GT1702 vitre est sur représenté. Il s'agit d'un article de PLV (une sorte de frigo), qui coûte 495€ pour lequel le poids de la ligne remonte à 1kg (d'où un pmvk décalé). Il s'agissait d'une erreur sur le poids de l'article, qui a été ensuite corrigée.\n",
    "\n",
    "On va à nouveau clipper cette donnée, sachant qu'il y aura une incohérence sur les lignes corrigées entre PMVK, CA brut et poids (on ne souhaite pas modifier CA brut ou poids)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmvk_clip = clipvalue(df.loc[:, 'pmvk'], stdcount=3)\n",
    "pmvk_clip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['pmvk_clipped'] = df['pmvk'].clip(lower=-pmvk_clip, upper=pmvk_clip)\n",
    "df[['pmvk', 'pmvk_clipped']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.kdeplot(df['pmvk_clipped'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Au-delà de l'artefact de droite dû au \"clippage\", on a une courbe plutôt irrégulière..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse détaillée des ratios entre eux\n",
    "\n",
    "On passe sur une visualisation de la densité du noyau pour mieux voir la répartition des points sur le dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.PairGrid(df.loc[:, ['brutrevenue_clipped', 'weight_clipped', 'margin_clipped', 'pmvk_clipped']].sample(5000))\n",
    "g = g.map_offdiag(sns.kdeplot, shade=True, shade_lowest=False)\n",
    "g = g.map_diag(sns.distplot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que même après avoir réduit les extremums, les points sont concentrés dans un tout petit espace. De plus, la répartition des poids des postes montre des irrégularités curieuses.\n",
    "\n",
    "Si on zoome sur les zones représentatives, on obtient la visualisation suivante :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "g.axes[0,1].set_ylim(-5, 65)\n",
    "g.axes[0,2].set_xlim(-3, 20)\n",
    "g.axes[1,0].set_ylim(-1, 13)\n",
    "g.axes[1,0].set_xlim(-5, 50)\n",
    "g.axes[2,1].set_ylim(-3, 20)\n",
    "g.axes[2,1].set_xlim(-1, 7)\n",
    "g.axes[0,3].set_xlim(-3, 17)\n",
    "g.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Globalement, on voit bien que les données sur les 3 premiers ratios semblent linéairement corrélées (les tâches sont plutôt le long d'une droite y = ax). Néanmoins, il y a une \"verrue\", qu'on voit par exemple aux alentours de weight = 5 et brutrevenue = 15.\n",
    "\n",
    "Les irrégularités sur la courbe du poids (le graphe central, sur lequel on voit un second maximum local) sont sur des lignes qui doivent avoir un PMVK qui est plus faible (poids plus important, mais CA à peu près similaire)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hue_var = 'Grpe de marchandises'\n",
    "sample_size = 5000\n",
    "\n",
    "df_plot = df.loc[:, ['brutrevenue_clipped', 'weight_clipped', 'margin_clipped', 'pmvk_clipped', hue_var]].sample(sample_size)\n",
    "print(df_plot.groupby(hue_var).count())\n",
    "print(df_plot[hue_var].cat.categories)\n",
    "df_plot[hue_var].cat.remove_unused_categories(inplace=True)\n",
    "print(df_plot[hue_var].cat.categories)\n",
    "df_plot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g2 = sns.PairGrid(df_plot, hue=hue_var)\n",
    "#g2 = g2.map_offdiag(sns.kdeplot,shade=True, shade_lowest=False, alpha=0.5)\n",
    "#g2 = g2.map_diag(sns.kdeplot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#g2.axes[0,1].set_ylim(-5, 65)\n",
    "#g2.axes[0,2].set_xlim(-3, 20)\n",
    "#g2.axes[1,0].set_ylim(-1, 13)\n",
    "#g2.axes[1,0].set_xlim(-5, 50)\n",
    "#g2.axes[2,1].set_ylim(-3, 20)\n",
    "#g2.axes[2,1].set_xlim(-1, 7)\n",
    "#g2.axes[0,3].set_xlim(-3, 17)\n",
    "#g2 = g2.add_legend()\n",
    "#g2.fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse par jour de la semaine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekday'] = df['date'].dt.weekday + 1\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print(df.groupby('weekday')['client'].count())\n",
    "ax = df.groupby('weekday')['client'].count().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour éviter d'avoir des effets de bord lors de l'affichage temporel, on droppe les lignes qui concernent des samedis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('weekday').size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['weekday'] != 6].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('weekday').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On calcule le nombre de postes par jour et le nombre de commandes par jour. On peut d'abord définir une liste d'axes complémentaires pour l'analyse, en listant les critères dans la liste suivantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crit_list = ['flag_reco']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_postes = df.groupby(['date'] + crit_list).size()\n",
    "df_postes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_commandes = df.groupby(['date', 'client'] + crit_list).size().groupby(['date'] + crit_list).size()\n",
    "df_commandes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commandes = pd.concat([df_commandes, df_postes], axis=1)\n",
    "df_commandes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commandes.columns = ['commandes', 'postes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_commandes['nb_moy_lig'] = df_commandes['postes'] / df_commandes['commandes']\n",
    "df_commandes.reset_index(inplace=True)\n",
    "df_commandes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df_commandes[['commandes', 'postes', 'date']].groupby('date').sum()\n",
    "df_agg['nb_moy_lig'] = df_agg['postes'] / df_agg['commandes']\n",
    "ax = df_agg['nb_moy_lig'].plot(kind='line', figsize=(13, 8))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df_agg.rolling(window=15, min_periods=0).mean()['nb_moy_lig'].plot(kind='line', figsize = (13, 8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il semblerait qu'il y ait une saisonnalité au niveau de cet indicateur. On affiche en empilant les données année par année pour se faire une idée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg.reset_index(inplace=True)\n",
    "df_agg['year'] = df_agg['date'].apply(lambda x: x.year)\n",
    "df_agg['dayofyear'] = df_agg['date'].apply(lambda x: x.dayofyear)\n",
    "df_agg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13,8))\n",
    "for year_ in [2017, 2018, 2019]:\n",
    "    df_plot = df_agg.loc[df_agg['year'] == year_].reset_index(drop=True).rolling(window=15, min_periods=3).mean()\n",
    "    line, = ax.plot(df_plot['dayofyear'], df_plot['nb_moy_lig'])\n",
    "    line.set_label(str(year_))\n",
    "ax.legend()\n",
    "ax.set_title(\"Nombre de lignes par commande - Comparatif entre années\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(13, 8))\n",
    "labels = ['Sans recos', 'Avec recos']\n",
    "for i in range(2):\n",
    "    df2 = df_commandes.loc[df_commandes.flag_reco == i].set_index('date').rolling(window=15, min_periods=3).mean().reset_index()\n",
    "    line, = ax.plot(df2['date'].dt.to_pydatetime(), df2['nb_moy_lig'])\n",
    "    line.set_label(labels[i])\n",
    "ax.legend()\n",
    "ax.axvline(x=pd.to_datetime('20190930'), color='green')\n",
    "#ax.set_xlim(pd.to_datetime('20181101'))\n",
    "ax.set_title(\"Nombre de lignes par commande - Comparatif A/B test\", fontsize=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.set_ylim(0)\n",
    "ax.figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse des recos \"trop similaires\"\n",
    "\n",
    "On va identifier les recommandations \"trop similaires\" à des produits déjà récurrents.\n",
    "\n",
    "On commence par calculer les produits récurrents par client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rank_commandes_par_resto'] = df.groupby('client')['date'].rank('dense', ascending=False)\n",
    "ds3 = df.loc[df['rank_commandes_par_resto']<=12].groupby(['client', 'material']).size()\n",
    "ds3 = ds3.rename('order_count_last_12')\n",
    "ds3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = df.merge(ds3.reset_index(), how='left', on=['client', 'material'], validate='m:1')\n",
    "df['order_count_last_12'].fillna(0, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A Voir, à priori inutile\n",
    "#df2 = df[df.groupby(['client', 'Hiérarchie produit'], observed=True)['order_count_last_12'].transform('max').eq(df['order_count_last_12'])]\n",
    "#df2[df2['order_count_last_12']>=3].tail()\n",
    "\n",
    "#df2 = df[df['order_count_last_12'] >= 3]\n",
    "#df3 = df_prev_reco.merge(df2, \n",
    "#                         how='inner',\n",
    "#                         left_on=['Code_client', 'Hiérarchie produit'],\n",
    "#                         right_on=['client', 'Hiérarchie produit'])\n",
    "\n",
    "#df3.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On construit une série qui permet de garder le nombre d'articles présents dans l'historique de chaque noeud de hiérarchie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myIndex = pd.Index([''])\n",
    "uniq = df['material'].nunique()\n",
    "ds = pd.Series(data=[uniq], index=myIndex)\n",
    "for myLen in range(1,7):\n",
    "    df['H'+str(myLen)] = df['Hiérarchie produit'].apply(lambda x: x[:(myLen*2)])\n",
    "    ds = pd.concat([ds, df.groupby(['material', 'H' + str(myLen)]).size().groupby('H' + str(myLen)).size()])\n",
    "ds.sort_index(inplace=True)\n",
    "ds.head(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On écrit une fonction qui retourne la distance entre 2 articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mat_dist(mat1, mat2):\n",
    "    if mat1 == mat2:\n",
    "        return(0)\n",
    "    else:\n",
    "        myLen = 0\n",
    "        h1, h2 = df[df['material'] == mat1].iloc[0]['H6'], df[df['material'] == mat2].iloc[0]['H6']\n",
    "        while(h1[:(myLen*2)] == h2[:(myLen*2)]) and myLen < 6:\n",
    "            myLen += 1\n",
    "        return(ds[h1[:((myLen-1)*2)]])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_dist('000000000000000433','000000000000000433')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "print(datetime.datetime.now())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
